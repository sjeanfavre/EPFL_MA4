{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LEPtxamkHxF9"
   },
   "source": [
    "# Assignment 4: Graph Neural Networks\n",
    "\n",
    "Contact: [William Cappelletti](mailto:william.cappelletti@epfl.ch), [Ying Cao](mailto:ying.cao@epfl.ch)\n",
    "\n",
    "Note that the classification sections are interchangeable, which means you do not have to run them sequentially to proceed.\n",
    "You can run each section independently, and only train the corresponding models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqMCtyeTE6KG"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-LF3x4LRIdpe"
   },
   "outputs": [],
   "source": [
    "#!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.11.0+cu113.html\n",
    "\n",
    "#!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OCA8uz1KE4NS"
   },
   "outputs": [],
   "source": [
    "from typing import Callable, List, Optional\n",
    "\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torch_geometric as pyg\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch_geometric.data import Dataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import GNNBenchmarkDataset, Planetoid\n",
    "from torch_geometric.utils import from_networkx, to_networkx, get_laplacian\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q80r1xHhFDHg"
   },
   "source": [
    "To activate a GPU in colab , open the *Runtime* drop-down menu and click *Change runtime type*, then choose GPU as hardware accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "X-cJyFlRFFyD"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"No GPU :(\")\n",
    "    device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZIUs-ot-ovR"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Prerequisite: [Tutorial 3]()\n",
    "\n",
    "### Learning outcomes\n",
    "\n",
    "- Implement a GNN, from convolution to pooling layers\n",
    "- Use loss functions and training loops to train NNs on graph and node tasks\n",
    "- Understand the usual deep learning pipeline\n",
    "\n",
    "### Description\n",
    "\n",
    "In this assignment we will implement and test the building blocks of Graph Neural Networks.\n",
    "We will see how different elements work together to create embeddings out of network data.\n",
    "Then, we shall use those embeddings to solve a few tasks.\n",
    "\n",
    "The idea is to define a few (at least two) different embedding blocks and use them as the core of GNNs for the main networks problems, such as node and graph classification.\n",
    "\n",
    "1. Graph classification: Graph MNIST\n",
    "2. Node classification: Cora citation dataset\n",
    "\n",
    "\n",
    "### Structure of the notebook:\n",
    "\n",
    "#### 1. Graph convolution\n",
    "\n",
    "1. Implement the *Laplacian-polynomial convolution*\n",
    "2. *Test it* on a sample graph and comment on input/output\n",
    "\n",
    "#### 2. Node embedding\n",
    "\n",
    "- *Define modules* to compute node embeddings.\n",
    "    These will be the building blocks of the specific GNNs.\n",
    "\n",
    "#### 3. For each of the two tasks\n",
    "\n",
    "##### 3.1 Pooling (completing the GNN)\n",
    "\n",
    "- Define one GNNs for each task. They will use the node-embedding modules as inner blocks and have different readout layers.\n",
    "\n",
    "##### 3.2 Training\n",
    "\n",
    "- Two training loops shall be implemented, since for graph classification we have distinct graphs, while for node classification we have to use disjoint masks to extract train/test/val.\n",
    "\n",
    "##### 3.3 Evaluation\n",
    "\n",
    "- Write an evaluation loop\n",
    "- Compute training (and validation) accuracy\n",
    "\n",
    "##### 3.4 Discussion\n",
    "\n",
    "- Evaluate your architectures\n",
    "- Try some hyperparameters\n",
    "- Compare.\n",
    "\n",
    "This exercise will be an open question where you discuss how different models and parameters perform.\n",
    "It should include at least the following points:\n",
    "\n",
    "- *Learning rate*: how does it affect training and evaluation performances and why?\n",
    "- *Embedding dimension*: does the performance improve with size?\n",
    "- *Depth*:\n",
    "    - How does the number of layers affects fitting and generalization?\n",
    "    - How does depth affect the information flow over a graph?\n",
    "\n",
    "### Expected output\n",
    "\n",
    "You will have coding and theoretical questions. Coding exercises shall be solved within the specified space:\n",
    "```python\n",
    "# Your solution here ###########################################################\n",
    "...\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "```\n",
    "Anything outside shall not be touched, except if otherwise stated.\n",
    "\n",
    "Theoretical questions shall be answered between the two horizontal lines (`---`) following the statement.\n",
    "Pay attention to leave a blank line before the triple dash, or Markdown will interpret it as a title.\n",
    "\n",
    "For instance:\n",
    "\n",
    "---\n",
    "*Your answer here*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-isMyxBFgJe",
    "tags": []
   },
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUYG92a94Yk6"
   },
   "source": [
    "Nothing to do here, just defining a dataset that we will use later ðŸ˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fspQdxj7HpRS"
   },
   "outputs": [],
   "source": [
    "class GraphMNIST(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        dist_p: float = 2,\n",
    "        train: bool = True,\n",
    "        download: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dist_p = dist_p\n",
    "        self.img_size = 28\n",
    "\n",
    "        self._mnist_transform = transforms.ToTensor()\n",
    "        self._mnist = MNIST(root, transform=self._mnist_transform, train=train, download=download)\n",
    "\n",
    "        self._pos_perm = torch.tensor([[0.,-1.], [1.,0.]], dtype=torch.float) \n",
    "        self._pos_off = torch.tensor([0., self.img_size], dtype=torch.float)\n",
    "    \n",
    "    def get(self, index: int) -> Data:\n",
    "        x, y = self._mnist[index]\n",
    "        x = x[0]\n",
    "\n",
    "        nz = x.nonzero()\n",
    "        # x = x[nz[:,0], nz[:,1]]\n",
    "\n",
    "        nz = nz.to(torch.float)\n",
    "\n",
    "        # Manhattan ngbs\n",
    "        # edge_index = (torch.cdist(nz, nz, p=1) == 1).nonzero().T\n",
    "        # Euclidean ngbs\n",
    "        cdists = torch.cdist(nz, nz, p=self.dist_p)\n",
    "        edge_index = ((0 < cdists) & (cdists < 2)).nonzero().T\n",
    "\n",
    "        # We forse pos to be between -1 and 1\n",
    "        pos = (\n",
    "            nz @ self._pos_perm\n",
    "            + self._pos_off\n",
    "        ) / (self.img_size / 2) - 1 \n",
    "\n",
    "        return Data(\n",
    "            x=pos,\n",
    "            edge_index=edge_index,\n",
    "            y=y,\n",
    "        )\n",
    "\n",
    "    def len(self) -> int:\n",
    "        return len(self._mnist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFjPsqsFooXW"
   },
   "source": [
    "## 1. Graph convolution\n",
    "\n",
    "In this section we will implement and analyze a particular example of convolution on graphs, building on what you have seen in class.\n",
    "\n",
    "The **Laplacian Polynomial convolution** is defined as\n",
    "$$ f(X) = \\sum_i L^i X \\theta_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dSEV7F19rsk"
   },
   "source": [
    "### Exercise\n",
    "\n",
    "It is time to implement the convolution as a neural network layer, to be used with PyTorch Geometric data.\n",
    "\n",
    "Our layer will be a subclass of [`torch_geometric.nn.conv.MessagePassing`][messagepass], which is a subclass of [`torch.nn.module`][nn.module] to achieve message propagation in graph neural networks.\n",
    "As we have seen in the tutorial, we only need to implement the `__init__` and the `forward` methods.\n",
    "The forward method must follow the PyTorch Geometric API, i.e. it should expect features `x` and the edge list from the `Data` class.\n",
    "\n",
    "We provided the backbone of the class, it's your turn to populate the methods!\n",
    "\n",
    "[messagepass]: https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html#the-messagepassing-base-class\n",
    "[nn.module]: https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "h4o9dm_MowSk"
   },
   "outputs": [],
   "source": [
    "class LaplacianConv(MessagePassing):\n",
    "    def __init__(self, in_features, out_features, K) -> None:\n",
    "        \"\"\" Convolution defined as a polinomial of the Laplacian.\n",
    "\n",
    "        Arguments:\n",
    "            in_features (int): dimension of the input features\n",
    "            out_features (int): dimension of the output features\n",
    "            K (int): order of the Laplacian polynomial\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Your solution here ###################################################\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self._K = K\n",
    "\n",
    "        # Init weights\n",
    "        self.lins = torch.nn.ModuleList([\n",
    "            Linear(in_channels, out_channels, bias=False,\n",
    "                   weight_initializer='glorot') for _ in range(K)\n",
    "        ])\n",
    "        # What about bias?\n",
    "        \n",
    "        #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor):\n",
    "        # Your solution here ###################################################\n",
    "        # hint: you may use the get_laplacian function and the propogation operation in torch.geometric package.\n",
    "        # feel free to use other methods without the need to use MessagePassing\n",
    "        \n",
    "        Tx_0 = x\n",
    "        Tx_1 = x  # Dummy.\n",
    "        out = self.lins[0](Tx_0)\n",
    "\n",
    "        # propagate_type: (x: Tensor, norm: Tensor)\n",
    "        if len(self.lins) > 1:\n",
    "            Tx_1 = self.propagate(edge_index, x=x, norm=norm, size=None)\n",
    "            out = out + self.lins[1](Tx_1)\n",
    "\n",
    "        for lin in self.lins[2:]:\n",
    "            Tx_2 = self.propagate(edge_index, x=Tx_1, norm=norm, size=None)\n",
    "            Tx_2 = 2. * Tx_2 - Tx_0\n",
    "            out = out + lin.forward(Tx_2)\n",
    "            Tx_0, Tx_1 = Tx_1, Tx_2\n",
    "\n",
    "        return out\n",
    "        #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # Your solution here ###################################################\n",
    "        return norm.view(-1, 1) * x_j\n",
    "        #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxgSZAV0A-cw"
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Let's study the effect of this convolution on a sample input. Run the following cell a few times, playing with the parameters. You should understand how this convolution affects each node representation and answer the following questions with your intuitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "K-eqVc7PCaHR",
    "outputId": "381010c3-9de2-4a0d-8501-e266abcea118"
   },
   "outputs": [],
   "source": [
    "NB_NODES = 8\n",
    "G = nx.cycle_graph(n=NB_NODES)\n",
    "pos = nx.circular_layout(G)\n",
    "\n",
    "sample_cycle = from_networkx(G)\n",
    "_x = torch.zeros((NB_NODES, 1))\n",
    "_x[0,0] = 1\n",
    "sample_cycle.x = _x\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12,6))\n",
    "nx.draw(G, pos=pos, node_color=_x.flatten().tolist(), ax=axes[0,0], vmin=-1, vmax=1)\n",
    "\n",
    "L = nx.laplacian_matrix(G)\n",
    "axes[1,0].spy(L**0)\n",
    "axes[1,0].set(title=\"$L^0$\", xticks=[], yticks=[])\n",
    "\n",
    "for k in range(1, 1):\n",
    "    conv = LaplacianConv(1, 1, k)\n",
    "    _x = conv(sample_cycle.x, sample_cycle.edge_index)\n",
    "\n",
    "    nx.draw(G, pos=pos, node_color=_x.flatten().tolist(), ax=axes[0, k], vmin=-1, vmax=1)\n",
    "    axes[0, k].set(title=f\"Conv(k={k})\")\n",
    "\n",
    "    axes[1,k].spy(L**k)\n",
    "    axes[1,k].set(title=f\"$L^{k}$\", xticks=[], yticks=[])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0GSfS4jCat3"
   },
   "source": [
    "The figure above shows, in the first row, the effect of the convolution you coded on a simple input graph (an 8-cycle with its signal concentrated in a single point). \n",
    "The second row shows various powers of the Laplacian.\n",
    "\n",
    "**Question:** What does the degree of the Laplacian polynomial represent, in terms of information propagation?\n",
    "\n",
    "---\n",
    "The degree of the Laplacian defines the depth of the information propagation for each node for a single graph convolution layer. For instance, K=2 means that each convolution take into account the 1- and 2-hops neighbors when propagating the message.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VslCVwPxCscJ"
   },
   "source": [
    "**Question:** Explain in your own words what is the effect of this convolution.\n",
    "\n",
    "\n",
    "---\n",
    "*Your solution here*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1xz8X9WEifY"
   },
   "source": [
    "## 2. Node embeddings\n",
    "\n",
    "As you have seen in class, GNNs are parametrized functions of nodes features.\n",
    "The output of a GNN layer is almost always a new set of features for the same\n",
    "graph. By composing layers one after the other, our function becomes more\n",
    "expressive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-3ojZWmMrbR"
   },
   "source": [
    "### Exercise\n",
    "\n",
    "In the following cells, define at least two GNN blocks based on the PyTorch Geometric API. \n",
    "You can add some hyperparameters to the constructor, to allow for more flexibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cb9K1sWSLZIb"
   },
   "outputs": [],
   "source": [
    "class GNNBlock1(nn.Module):\n",
    "    def __init__(self, nb_features: int, embedding_dim: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # Your solution here ###################################################\n",
    "        # Feel free to add arguments if you need them, but provide default\n",
    "        # values so that our examples still works\n",
    "        self.conv1 = pyg.nn.GraphConv(...)\n",
    "        ...\n",
    "\n",
    "        #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Your solution here ###################################################\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        ...\n",
    "\n",
    "        #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lRDwxDk3LqOu"
   },
   "outputs": [],
   "source": [
    "class GNNBlock2(nn.Module):\n",
    "    # Your solution here #######################################################\n",
    "    ...\n",
    "\n",
    "    #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ki7QboWs4WEV"
   },
   "source": [
    "Let's test our GNN blocks on the sample cycle we defined before.\n",
    "We choose an embedding dimension of 16, and thus we expect the output to be of shape `(8, 16)`, which represents the embedding of the eight nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R6OMNFKH4Vg2"
   },
   "outputs": [],
   "source": [
    "gnn_block1 = GNNBlock1(nb_features=1, embedding_dim=16)\n",
    "\n",
    "out = gnn_block1(sample_cycle.x, sample_cycle.edge_index)\n",
    "assert out.shape == (8,16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8nXmUZdNNkl"
   },
   "source": [
    "## 3. Graph Classification\n",
    "\n",
    "In this section we will use the two GNN blocks that we just defined to build a graph classifier.\n",
    "First, we construct the model, then we define a training loop, and finally we evaluate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CaAwLbJw088l"
   },
   "source": [
    "### Exercise : Pooling\n",
    "\n",
    "Complete the following module by pooling the nodes representations with one of the methods defined in [`torch_geometric.nn`][pyg.nn].\n",
    "We already imported `torch_geometric` as `pyg`.\n",
    "\n",
    "[pyg.nn]: https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VVvXyksVNQhd"
   },
   "outputs": [],
   "source": [
    "class GraphClassifier(nn.Module):\n",
    "    def __init__(self, gnn_block: nn.Module, embedding_dim: int, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "        self.gnn_block = gnn_block\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_dim, num_classes),\n",
    "        )\n",
    "        # Your solution here ###################################################\n",
    "        self.pooling = ...\n",
    "\n",
    "        #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "    \n",
    "    def forward(self, x, edge_index, batch) -> torch.Tensor:\n",
    "        x = self.gnn_block(x, edge_index)\n",
    "        x = self.pooling(x, batch)\n",
    "\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgrVxCiWmd3T"
   },
   "source": [
    "Again, let's verify the output of the graph classifier on the sample cycle that we define above.\n",
    "The following cell defines a graph classifier using the `GNNBlock1`, to predict over two classes.\n",
    "We expect the output to be of shape `(1,2)`, which represents the logits for two classes of a single graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "maiP8r9aJAPE"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 5\n",
    "\n",
    "graph_gnn = GraphClassifier(\n",
    "    GNNBlock1(sample_cycle.x.shape[1], EMBEDDING_DIM),\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    num_classes=2,\n",
    ")\n",
    "\n",
    "out = graph_gnn(sample_cycle.x, sample_cycle.edge_index, batch=None)\n",
    "print(out)\n",
    "assert out.shape == (1,2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QO8Pn5NTzEn4"
   },
   "source": [
    "### Exercise : Training\n",
    "\n",
    "Having defined the model, we now have to train it for some task.\n",
    "We will work with a graph version of the MNIST handwritten-digit dataset.\n",
    "Each sample is a graph given by adjacent colored pixels (the nodes), as you can see in the image below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TNCIGvfAVxAJ"
   },
   "outputs": [],
   "source": [
    "dataset_tr = GraphMNIST(\".\", dist_p=2, train=True, download=True)        \n",
    "dataset_te = GraphMNIST(\".\", dist_p=2, train=False, download=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-c1fmhlWFFu"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,5, figsize=(26,4))\n",
    "for i in range(5):\n",
    "    g = dataset_tr[i]\n",
    "    G = to_networkx(g, to_undirected=True)\n",
    "\n",
    "    nx.draw(\n",
    "        G,\n",
    "        pos=g.x.numpy(),\n",
    "        node_shape='.',\n",
    "        ax=ax[i],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncFfQ1PWFtmF"
   },
   "source": [
    "Define a function to train graph-level tasks.\n",
    "It should take as input a model, a data loader, a loss function, an optimizer and a number of epochs.\n",
    "\n",
    "Then, complete the next cell by declaring all missing variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sae0JIT8F6Ra"
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    loss_fn: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    nb_epochs: int,\n",
    "):\n",
    "    # Your solution here #######################################################\n",
    "    ...\n",
    "\n",
    "    #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGFvHN84e-_3"
   },
   "outputs": [],
   "source": [
    "# Your solution here ###########################################################\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = ...\n",
    "\n",
    "model = GraphClassifier(\n",
    "    ...\n",
    ")\n",
    "\n",
    "loss_fn = ...\n",
    "\n",
    "optimizer = ...\n",
    "\n",
    "nb_epochs = ...\n",
    "\n",
    "train(model, train_loader, loss_fn, optimizer, nb_epochs)\n",
    "\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHcO4pXUOOzY"
   },
   "source": [
    "### Exercise : Evaluation\n",
    "\n",
    "Let's evaluate the trained model(s).\n",
    "For this purpose we can use metrics from the [TorchMetrics][TorchMetrics] package. \n",
    "\n",
    "Let's write a function that evaluates a trained model for a given metric, over a certain data loader.\n",
    "Fill the body in the next cell.\n",
    "\n",
    "[TorchMetrics]: https://torchmetrics.readthedocs.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HmU-K4NXAmTM"
   },
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, metric: torchmetrics.Metric, loader: DataLoader):\n",
    "    model.eval()  # Deactivate dropout\n",
    "    with torch.no_grad():\n",
    "        # Your solution here ###################################################\n",
    "        ...\n",
    "\n",
    "        #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "    return metric.compute().item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChiJNDxenBqN"
   },
   "source": [
    "Now, let's compute the training accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4m3rtftOMod"
   },
   "outputs": [],
   "source": [
    "accuracy_fn_tr = torchmetrics.Accuracy().to(device)\n",
    "print(\"Train accuracy:\", evaluate(model, accuracy_fn_tr, train_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lp4mWtvu7Tbb"
   },
   "source": [
    "### Exercise: Discussion\n",
    "\n",
    "At this point we should have a complete pipeline!\n",
    "\n",
    "We can play with hyperparameters such as the *learning rate* and the *embedding dimension*.\n",
    "Also, we can change the architecture of our model, for instance by changing the embedding block with `GNNBlock2`.\n",
    "\n",
    "**Question**: How do different parameters affect your training scores? Which architecture is the best?\n",
    "\n",
    "---\n",
    "*Your answer here*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sy_Ws5UY8lCI"
   },
   "source": [
    "Now, let's test our final model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OjsRhJYj8ABA"
   },
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset_te, batch_size=BATCH_SIZE)\n",
    "accuracy_fn_te = torchmetrics.Accuracy().to(device)\n",
    "\n",
    "print(\"Test accuracy:\", evaluate(model, accuracy_fn_te, test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7k_53--mm00Q"
   },
   "source": [
    "## 4. Node classification\n",
    "\n",
    "In this section, instead of having multiple graphs with a label each, we have a single graph and node-wise annotations.\n",
    "We will work with a subset of the Cora dataset, available in [`torch_geometric.datasets.Planetoid`][planetoid].\n",
    "\n",
    "[planetoid]: https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRcGQV9Fc9Oy"
   },
   "outputs": [],
   "source": [
    "dataset = Planetoid(\".\", \"Cora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kw5V9pWofHyS"
   },
   "source": [
    "Each node is a scientific paper of one of 7 classes.\n",
    "Links are given by citations.\n",
    "The graph has 2708 nodes with 1433 features.\n",
    "Feature vectors represent the embedding of the content of each paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFOYIp6VSPAt"
   },
   "outputs": [],
   "source": [
    "data = dataset[0]\n",
    "print(data)\n",
    "print(data.num_node_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2bFguptqp2_"
   },
   "source": [
    "### Exercise : Embedding\n",
    "\n",
    "Similarly to previous section, we will define a model containing our GNN block.\n",
    "The main difference will be in the pooling layer, since now we want to extract the representation of each node.\n",
    "\n",
    "Think about the GNN block. What is the shape of its output? What does it represent?\n",
    "\n",
    "In the following cell, you will find a class which is lacking its body, fill it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hnw5NgCoqvNb"
   },
   "outputs": [],
   "source": [
    "class NodeClassifier(nn.Module):\n",
    "    # Your solution here #######################################################\n",
    "\n",
    "    def __init__(self, gnn_block: nn.Module, embedding_dim: int, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "        ...\n",
    "\n",
    "    \n",
    "    def forward(self, x, edge_index) -> torch.Tensor:\n",
    "        ...\n",
    "\n",
    "        return x\n",
    "\n",
    "    #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcNzSIefgm29"
   },
   "source": [
    "### Exercise : Training\n",
    "\n",
    "As we have seen in the tutorial, to split the dataset in train and test we have to use masks.\n",
    "Luckily, standard datasets come with predefined splits, which we can access with `data.train_mask` and `data.test_mask`.\n",
    "\n",
    "As before, write a function that trains the model on a given graph, by using the training mask.\n",
    "Then, use such function to train a node classifier on the Cora graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0kXRCbrhnEr"
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    data: Data,\n",
    "    loss_fn: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    nb_epochs: int,\n",
    "):\n",
    "    # Your solution here #######################################################\n",
    "    ...\n",
    "\n",
    "    #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-BtMkYwIh8dM"
   },
   "outputs": [],
   "source": [
    "# Your solution here ###########################################################\n",
    "model = NodeClassifier(\n",
    "    ...\n",
    ")\n",
    "\n",
    "loss_fn = ...\n",
    "\n",
    "optimizer = ...\n",
    "\n",
    "nb_epochs = ...\n",
    "\n",
    "train(model, data, loss_fn, optimizer, nb_epochs)\n",
    "\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaWjUPnRiGEd"
   },
   "source": [
    "### Exercise: Evaluation\n",
    "\n",
    "Again, we have to revisit our evaluation function. We should now allow to pass a desired mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SLessDkTjgKk"
   },
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, metric: torchmetrics.Metric, data: Data, mask: torch.Tensor):\n",
    "    model.eval()  # Deactivate dropout\n",
    "    with torch.no_grad():\n",
    "        # Your solution here ###################################################\n",
    "        ...\n",
    "        \n",
    "        #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "    return metric.compute().item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzXnc8J3jgKm"
   },
   "source": [
    "Now, let's compute the accuracy on both training and validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Sc2r6nVjgKn"
   },
   "outputs": [],
   "source": [
    "# Your solution here ###########################################################\n",
    "\n",
    "accuracy_train = evaluate(model, ..., data, ...)\n",
    "accuracy_val = ...\n",
    "\n",
    "print(\"Train accuracy:\", accuracy_train)\n",
    "print(\"Val accuracy:\", accuracy_val)\n",
    "#^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAsdt7o38u88"
   },
   "source": [
    "### Exercise: Discussion\n",
    "\n",
    "Again, we have a complete pipeline. Play again with your hyperparameters and architecture, then answer the question.\n",
    "\n",
    "**Question**: How do different parameters affect your training scores? Which architecture is the best?\n",
    "\n",
    "---\n",
    "*Your answer here*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ri0fZxKk8u89"
   },
   "source": [
    "Let's test our final model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZ3ZUiG78u8-"
   },
   "outputs": [],
   "source": [
    "print(\"Test accuracy:\", evaluate(model, torchmetrics.Accuracy().to(device), data, data.test_mask))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "wZIUs-ot-ovR"
   ],
   "name": "assignment4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
