{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a52d20b9",
   "metadata": {
    "id": "a52d20b9"
   },
   "source": [
    "# Assignment 2: spectral graph theory and graph signal processing\n",
    "\n",
    "**Deadline: April 24th**\n",
    "\n",
    "This assignment features three exercices: \n",
    "  - label propagation\n",
    "  - spectral clustering\n",
    "  - spectral graph filtering\n",
    "\n",
    "We will need a package called [basemap](https://basemaptutorial.readthedocs.io/en/latest/) that provides a map of earth. This package can be installed in a conda environment by running:\n",
    "\n",
    "`conda install -c conda-forge basemap`\n",
    "\n",
    "\n",
    "If you don't manage to install this package, simply print all the plots without the background.\n",
    "\n",
    "After installing the package, the following lines may be needed:\n",
    "\n",
    "```\n",
    "import os\n",
    "import conda\n",
    "conda_file_dir = conda.__file__\n",
    "conda_dir = conda_file_dir.split('lib')[0]\n",
    "proj_lib = os.path.join(os.path.join(conda_dir, 'share'), 'proj')\n",
    "os.environ[\"PROJ_LIB\"] = proj_lib\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3faf11a",
   "metadata": {
    "id": "a3faf11a"
   },
   "source": [
    "## Exercice 1: Spectral clustering on air routes\n",
    "\n",
    "In this exercice, we will perform spectral clustering on the flight routes network and analyze the influence of the graph on the obtained clusters.\n",
    "\n",
    "*For additional information on spectral clustering, we refer to this [tutorial paper](http://www.tml.cs.uni-tuebingen.de/team/luxburg/publications/Luxburg07_tutorial.pdf). For practical aspects of the algorithm, the relevant sections are 1, 2, 3, 4, 8.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe026b0",
   "metadata": {
    "id": "3fe026b0"
   },
   "source": [
    "### Load and visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b8fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba55ebb0",
   "metadata": {
    "id": "ba55ebb0"
   },
   "outputs": [],
   "source": [
    "airports = pd.read_csv(\"./airports_cleaned.csv\")\n",
    "dists_df = pd.read_csv(\"./dists.csv\")\n",
    "\n",
    "# Create graph from distances dataframe\n",
    "G_full = nx.from_pandas_edgelist(dists_df,  \"source_airport_id\", \"destination_airport_id\", [\"distance\"])\n",
    "\n",
    "airport_ids_full = airports['airport_id'].to_numpy()\n",
    "\n",
    "lat_full = airports['Latitude'].to_numpy()[:, np.newaxis]\n",
    "long_full = airports['Longitude'].to_numpy()[:, np.newaxis]\n",
    "\n",
    "n_clusters = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dfe34e",
   "metadata": {
    "id": "e0dfe34e"
   },
   "outputs": [],
   "source": [
    "dists_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3fa031",
   "metadata": {
    "id": "3d3fa031"
   },
   "outputs": [],
   "source": [
    "airports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f5b436",
   "metadata": {
    "id": "47f5b436"
   },
   "outputs": [],
   "source": [
    "def plot_map(longitude, latitude, predictions=None, title=None):\n",
    "    \"\"\" longitude: np.array\n",
    "        latitude: np.array of the same length\n",
    "        predictions (optional): numpy array of int corresponding to cluster assignment. \"\"\"\n",
    "    plt.figure(figsize=(12,6))\n",
    "    m=Basemap()\n",
    "    m.drawcoastlines()                                     # Show the coast lines\n",
    "    plt.scatter(longitude, latitude, c=predictions)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_map(long_full, lat_full, title=\"All airports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3ba78e",
   "metadata": {
    "id": "ed3ba78e"
   },
   "source": [
    "### Part 1: K-means\n",
    "\n",
    "**Question 1 (code): Run K-means with 5 clusters on this data.**\n",
    "\n",
    "You can use the scikit learn function (https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bd6104",
   "metadata": {
    "id": "e6bd6104"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "y_pred_k_means= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab156606",
   "metadata": {
    "id": "ab156606"
   },
   "outputs": [],
   "source": [
    "plot_map(long_full, lat_full, predictions=y_pred_k_means, title=f\"K means with {n_clusters} clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed622d07",
   "metadata": {
    "id": "ed622d07"
   },
   "source": [
    "**Question 2 (analysis): Why is the standard implementation of K-means not suited to data that lies on a sphere?**\n",
    "\n",
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45611c51",
   "metadata": {
    "id": "45611c51"
   },
   "source": [
    "### Part 2: Spectral clustering\n",
    "\n",
    "#### Data preprocessing\n",
    "The flight routes network is not connected. We will select the largest connected component and discard the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9955cd48",
   "metadata": {
    "id": "9955cd48"
   },
   "outputs": [],
   "source": [
    "def largest_component(G: nx.Graph):\n",
    "    \"\"\" Return the ids of the airports inside the largest connected component.\n",
    "        Input: G: networkx graph with n nodes\n",
    "        Returns: connected_airport_ids: list of int\n",
    "    \"\"\"\n",
    "    largest_connected_component = max(nx.algorithms.components.connected_components(G), key=len)\n",
    "    return G.subgraph(largest_connected_component)\n",
    "\n",
    "\n",
    "G = largest_component(G_full)\n",
    "mask = np.zeros(len(airport_ids_full), dtype=bool)\n",
    "\n",
    "for node in G.nodes:\n",
    "    row = np.nonzero(node == airport_ids_full)\n",
    "    if len(row) != 1:\n",
    "        raise ValueError(f\"Issue with node {node}: nonzero returns {row}\")\n",
    "    mask[row] = True\n",
    "    \n",
    "long = long_full[mask]\n",
    "lat = lat_full[mask]\n",
    "airport_ids = airport_ids_full[mask]\n",
    "A = nx.adjacency_matrix(G).toarray().astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1d5d31",
   "metadata": {
    "id": "eb1d5d31"
   },
   "source": [
    "**Question 3 (code): Fill `compute_laplacian`, `compute_number_connected_components`, `spectral decomposition`. These functions should work for any definition of the laplacian (combinatorial, symmetric normalized, random walk).**\n",
    "\n",
    "Warning: the eigendecomposition of a non symmetric matrix returns complex numbers, even if the imaginary part is in fact 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9322dc6a",
   "metadata": {
    "id": "9322dc6a"
   },
   "outputs": [],
   "source": [
    "def compute_laplacian(adjacency: np.ndarray, normalize: str):\n",
    "    \"\"\" normalize: can be None, 'sym' or 'rw' for the combinatorial, symmetric normalized or random walk Laplacians\n",
    "    Return:\n",
    "        L (n x n ndarray): combinatorial or symmetric normalized Laplacian.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def compute_number_connected_components(lamb: np.array, threshold: float):\n",
    "    \"\"\" lamb: array of eigenvalues of a Laplacian\n",
    "        Return:\n",
    "        n_components (int): number of connected components.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def spectral_decomposition(laplacian: np.ndarray):\n",
    "    \"\"\" Warning: the choice of the solver should depends on whether the laplacian is symmetric.\n",
    "        Return:\n",
    "        lamb (np.array): eigenvalues of the Laplacian\n",
    "        U (np.ndarray): corresponding eigenvectors.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b9252c",
   "metadata": {
    "id": "f9b9252c"
   },
   "outputs": [],
   "source": [
    "laplacian_comb = compute_laplacian(A, normalize=None)\n",
    "lamb_comb, U_comb = spectral_decomposition(laplacian_comb)\n",
    "\n",
    "laplacian_norm = compute_laplacian(A, normalize='sym')\n",
    "lamb_norm, U_norm = spectral_decomposition(laplacian_norm)\n",
    "\n",
    "laplacian_rw = compute_laplacian(A, normalize='rw')\n",
    "lamb_rw, U_rw = spectral_decomposition(laplacian_rw)\n",
    "lamb_rw = np.real(lamb_rw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48cc44e",
   "metadata": {
    "id": "c48cc44e"
   },
   "source": [
    "**Question 4 (code): Implement spectral clustering for the 3 possible definitions of the Laplacian.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae85d3d",
   "metadata": {
    "id": "9ae85d3d"
   },
   "outputs": [],
   "source": [
    "class SpectralClustering():\n",
    "    def __init__(self, n_classes: int, normalize: str):\n",
    "        self.n_classes = n_classes\n",
    "        self.normalize = normalize\n",
    "        self.clustering_method = None        # To fill\n",
    "        \n",
    "    def fit_predict(self, adjacency):\n",
    "        \"\"\" Your code should be correct both for the combinatorial\n",
    "            and the symmetric normalized spectral clustering.\n",
    "            Return:\n",
    "            y_pred (np.ndarray): cluster assignments.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f2812",
   "metadata": {
    "id": "726f2812"
   },
   "source": [
    "#### Case 1: Spectral clustering with the flight route unweighted adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79cd5cd",
   "metadata": {
    "id": "a79cd5cd"
   },
   "outputs": [],
   "source": [
    "spectral_clustering = SpectralClustering(n_classes=4, normalize=None)\n",
    "y_pred = spectral_clustering.fit_predict(A)\n",
    "\n",
    "spectral_clustering_sym = SpectralClustering(n_classes=4, normalize='sym')\n",
    "y_pred_sym = spectral_clustering_sym.fit_predict(A.astype(float))\n",
    "\n",
    "spectral_clustering_rw = SpectralClustering(n_classes=4, normalize='rw')\n",
    "y_pred_rw = spectral_clustering_rw.fit_predict(A.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758709cc",
   "metadata": {
    "id": "758709cc"
   },
   "outputs": [],
   "source": [
    "plot_map(long, lat, predictions=y_pred,\n",
    "         title=\"Spectral clustering on A with the combinatorial Laplacian\")\n",
    "\n",
    "plot_map(long, lat, predictions=y_pred_sym,\n",
    "         title=\"Spectral clustering on A with the symmetric normalized Laplacian\")\n",
    "\n",
    "plot_map(long, lat, predictions=y_pred_rw,\n",
    "         title=\"Spectral clustering on A with the random walk Laplacian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bb3ef2",
   "metadata": {
    "id": "06bb3ef2"
   },
   "source": [
    "Note that imbalanced clusters may not necessarily be due to a bug. In spectral clustering, there is no easy way to ensure that the predicted classes are balanced.\n",
    "\n",
    "**Question 5 (analysis): Are some clusters interpretable? Why don't we get something similar to K-means (where clusters approximately correspond to continents)?**\n",
    "\n",
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4135ba",
   "metadata": {
    "id": "8a4135ba"
   },
   "source": [
    "#### Spectral clustering on a distance-weighted matrix\n",
    "\n",
    "We will also run spectral clustering on a second adjacency matrix, where short flight routes have a larger edge weights that long routes. The following lines build the new adjacency matrix W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc949992",
   "metadata": {
    "id": "cc949992"
   },
   "outputs": [],
   "source": [
    "routes_distance_matrix = nx.adjacency_matrix(G, weight='distance').toarray()     \n",
    "\n",
    "matrix_mask = routes_distance_matrix > 0\n",
    "\n",
    "average_distance = np.mean(routes_distance_matrix[matrix_mask])\n",
    "sigma = 0.5 * average_distance                                    # width of the Gaussian kernel\n",
    "\n",
    "W = np.zeros(routes_distance_matrix.shape)\n",
    "W[matrix_mask] = np.exp(- routes_distance_matrix ** 2/ (2 * sigma ** 2))[matrix_mask] # Gaussian kernel\n",
    "W[matrix_mask * W < 0.0001] = 0.0001                       # Used to keep the graph connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db4726e",
   "metadata": {
    "id": "6db4726e"
   },
   "outputs": [],
   "source": [
    "spectral_clustering = SpectralClustering(n_classes=6, normalize=None)\n",
    "y_pred = spectral_clustering.fit_predict(W)\n",
    "\n",
    "spectral_clustering_sym = SpectralClustering(n_classes=6, normalize='sym')\n",
    "y_pred_sym = spectral_clustering_sym.fit_predict(W)\n",
    "\n",
    "spectral_clustering_rw = SpectralClustering(n_classes=6, normalize='rw')\n",
    "y_pred_rw = spectral_clustering_rw.fit_predict(W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f29028",
   "metadata": {
    "id": "c3f29028"
   },
   "outputs": [],
   "source": [
    "plot_map(long, lat, predictions=y_pred,\n",
    "         title=\"Spectral clustering on W with the combinatorial Laplacian\")\n",
    "\n",
    "plot_map(long, lat, predictions=y_pred_sym,\n",
    "         title=\"Spectral clustering on W with the symmetric normalized Laplacian\")\n",
    "\n",
    "plot_map(long, lat, predictions=y_pred_rw,\n",
    "         title=\"Spectral clustering on W with the random walk Laplacian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e63373c",
   "metadata": {
    "id": "3e63373c"
   },
   "source": [
    "**Question 6 (analysis): Are some clusters interpretable? How do the results differ from the ones obtained with the unweighted adjacency matrix A?**\n",
    "\n",
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0025a0d8",
   "metadata": {
    "id": "0025a0d8"
   },
   "source": [
    "# Exercice 2: spectral filtering\n",
    "\n",
    "This exercice covers basic notion of filtering in the graph Fourier domain. We will use a nearest-neighbor graph constructed from the Stanford Bunny point cloud included in the PyGSP library.\n",
    "We construct the normalized graph laplacians from the adjacency matrix and find its spectral decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cfad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygsp\n",
    "from pygsp.graphs import Bunny\n",
    "from mpl_toolkits.mplot3d import Axes3D # as Axes3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa54327d",
   "metadata": {
    "id": "aa54327d"
   },
   "outputs": [],
   "source": [
    "# Define the graph\n",
    "G = Bunny()\n",
    "adjacency = np.asarray(G.W.todense())\n",
    "n_nodes = adjacency.shape[0]\n",
    "\n",
    "\n",
    "def plot_bunny(x=None, title='', vlim=[-0.03, 0.03]):\n",
    "    \"\"\" PLot a signal x on the bunny graph. \"\"\"\n",
    "    fig = plt.gcf()\n",
    "    ax = plt.gca()\n",
    "    if not isinstance(ax, Axes3D):\n",
    "        ax = plt.subplot(111, projection='3d')\n",
    "    if x is not None:\n",
    "        x = np.squeeze(x)\n",
    "    p = ax.scatter(G.coords[:,0], G.coords[:,1], G.coords[:,2], c=x, marker='o',\n",
    "                   s=5, cmap='RdBu_r', vmin=vlim[0], vmax=vlim[1])\n",
    "    ax.view_init(elev=-90, azim=90)\n",
    "    ax.dist = 7\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(title)\n",
    "    if x is not None:\n",
    "        fig.colorbar(p)\n",
    "    plt.show()\n",
    "        \n",
    "        \n",
    "plt.subplot(111, projection='3d')\n",
    "plot_bunny()\n",
    "\n",
    "# Compute the normalized Laplacian\n",
    "laplacian = compute_laplacian(adjacency, normalize='sym')\n",
    "laplacian = (laplacian + laplacian.T) / 2    # Make sure the matrix is symmetric despite numerical errors\n",
    "lam, U = spectral_decomposition(laplacian)\n",
    "\n",
    "# This lines should normally not be needed, but it seems that not all eigenvalues are always sorted\n",
    "argsort = np.argsort(lam)\n",
    "lam = lam[argsort]\n",
    "U = U[:, argsort]\n",
    "\n",
    "# Eigenvalues plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(np.arange(len(lam)), lam)\n",
    "plt.title('Eigenvalues of $L_{norm}$')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot some eigenvectors of the graph\n",
    "plt.figure(figsize=(18, 9))\n",
    "plt.subplot(231, projection='3d')\n",
    "plot_bunny(x=U[:,0], title='Eigenvector #0')\n",
    "plt.subplot(232, projection='3d')\n",
    "plot_bunny(x=U[:,1], title='Eigenvector #1')\n",
    "plt.subplot(233, projection='3d')\n",
    "plot_bunny(x=U[:,2], title='Eigenvector #2')\n",
    "\n",
    "plt.subplot(234, projection='3d')\n",
    "plot_bunny(x=U[:,3], title='Eigenvector #3')\n",
    "plt.subplot(235, projection='3d')\n",
    "plot_bunny(x=U[:,10], title='Eigenvector #10')\n",
    "plt.subplot(236, projection='3d')\n",
    "plot_bunny(x=U[:,100], title='Eigenvector #100')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2832a473",
   "metadata": {
    "id": "2832a473"
   },
   "source": [
    "**Question 7 (analysis): How does the intuitive notion of \"smoothness\" relates to the eigenvalue corresponding to an eigenvector? How can the smoothness of a signal be measured?**\n",
    "\n",
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe845583",
   "metadata": {
    "id": "fe845583"
   },
   "source": [
    "**Question 8 (code): Implement the Graph Fourier Transform (GFT) of a graph signal and its inverse.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99df08ed",
   "metadata": {
    "id": "99df08ed"
   },
   "outputs": [],
   "source": [
    "def GFT(signal: np.array, U: np.ndarray):\n",
    "    \"\"\" signal: float array of size n.\n",
    "        U: matrix of size n x n containing one eigenvector per column.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def iGFT(fourier_coefficients: np.ndarray, U: np.ndarray):\n",
    "    \"\"\" fourier_coefficients: float array of size n, containing a signal represented in the spectral domain\n",
    "        U: matrix of size n x n containing one eigenvector per column.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f6c6e4",
   "metadata": {
    "id": "98f6c6e4"
   },
   "source": [
    "### Filtering\n",
    "We first define a signal `x`, and a noisy version of it `x_noisy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2b697a",
   "metadata": {
    "id": "9d2b697a"
   },
   "outputs": [],
   "source": [
    "x = G.coords[:, 0] + G.coords[:, 1] + 3 * G.coords[:, 2]\n",
    "x /= np.linalg.norm(x) \n",
    "\n",
    "noise = np.random.randn(n_nodes)\n",
    "noise /= np.linalg.norm(noise) \n",
    "\n",
    "x_noisy = x + 0.3 * noise\n",
    "\n",
    "plot_bunny(x_noisy, vlim=[min(x_noisy), max(x_noisy)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51c236",
   "metadata": {
    "id": "8a51c236"
   },
   "source": [
    "We will try to extract the signal from the noise using graph filters. Let us start by creating 4 ideal graph filters: a low pass, a band pass, a high pass, and the filter that implements the solution of Tikhonov regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0019ce6f",
   "metadata": {
    "id": "0019ce6f"
   },
   "outputs": [],
   "source": [
    "ideal_lp = np.ones((n_nodes,))\n",
    "ideal_bp = np.ones((n_nodes,))\n",
    "ideal_hp = np.ones((n_nodes,))\n",
    "\n",
    "ideal_lp[lam >= 0.1] = 0  # Low-pass filter with cut-off at lambda=0.1\n",
    "ideal_bp[lam < 0.1] = 0  # Band-pass filter with cut-offs at lambda=0.1 and lambda=0.5\n",
    "ideal_bp[lam > 0.5] = 0\n",
    "ideal_hp[lam <= 1] = 0  # High-pass filter with cut-off at lambda=1\n",
    "\n",
    "alpha = 0.99 / np.max(lam)\n",
    "\n",
    "ideal_tk = np.ones((n_nodes,))\n",
    "ideal_tk = 1 / (1 + alpha*lam)\n",
    "\n",
    "# Let's plot the spectral responses:\n",
    "\n",
    "plt.plot(lam, ideal_lp, '-', label='LP')\n",
    "plt.plot(lam, ideal_bp, '-', label='BP')\n",
    "plt.plot(lam, ideal_hp, '-', label='HP')\n",
    "plt.plot(lam, ideal_tk, '-', label='Tikhonov')\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('Spectral response')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33d3f13",
   "metadata": {
    "id": "b33d3f13"
   },
   "source": [
    "**Question 9 (code): Implement the filtering function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749a8fc",
   "metadata": {
    "id": "e749a8fc"
   },
   "outputs": [],
   "source": [
    "def filter_signal(x: np.array, spectral_response: np.array, U: np.ndarray):\n",
    "    \"\"\" Return a filtered signal\n",
    "        The filter is defined in the spectral domain by its value on each eigenvector\n",
    "        x (float array of size n): input signal\n",
    "        spectral response (float array of size n): value of the filter at each eigenvalue\n",
    "        U (n x n matrix): eigenvectors (one per column).\n",
    "        returns:\n",
    "        out (float array of size n): Filtered signal\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c8790",
   "metadata": {
    "id": "775c8790"
   },
   "outputs": [],
   "source": [
    "x_lp = filter_signal(x_noisy,ideal_lp, U)\n",
    "x_bp = filter_signal(x_noisy,ideal_bp, U)\n",
    "x_hp = filter_signal(x_noisy,ideal_hp, U)\n",
    "x_tk = filter_signal(x_noisy,ideal_tk, U)\n",
    "\n",
    "plt.figure(figsize=(18, 9))\n",
    "plt.subplot(231, projection='3d')\n",
    "plot_bunny(x=x, title='signal (true)', vlim=[min(x), max(x)])\n",
    "plt.subplot(232, projection='3d')\n",
    "plot_bunny(x=x_noisy, title='signal (noisy)', vlim=[min(x), max(x)])\n",
    "plt.subplot(233, projection='3d')\n",
    "plot_bunny(x=x_lp, title='Low-pass', vlim=[min(x_lp), max(x_lp)])\n",
    "plt.subplot(234, projection='3d')\n",
    "plot_bunny(x=x_bp, title='Band-pass', vlim=[min(x_bp), max(x_bp)])\n",
    "plt.subplot(235, projection='3d')\n",
    "plot_bunny(x=x_hp, title='High-pass', vlim=[min(x_hp), max(x_hp)])\n",
    "plt.subplot(236, projection='3d')\n",
    "plot_bunny(x=x_tk, title='Tikhonov denoised signal', vlim=[min(x_tk), max(x_tk)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5298e398",
   "metadata": {
    "id": "5298e398"
   },
   "source": [
    "**Question 10 (analysis): What kind of filter does Tikhonov regularization implement?**\n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf3b90a",
   "metadata": {
    "id": "4418f31a"
   },
   "source": [
    "## Exercice 3: Label propagation\n",
    "\n",
    "We will implement label propagation, which is an algorithm for semi-supervised learning: given a few labeled points, the goal is to assign labels to other points. We refer to [this paper](http://mlg.eng.cam.ac.uk/zoubin/papers/CMU-CALD-02-107.pdf) for the details about the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892d4516",
   "metadata": {
    "id": "fa80de06"
   },
   "outputs": [],
   "source": [
    "import pygsp.graphs\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bbabc1",
   "metadata": {},
   "source": [
    "We will use points sampled from the Swiss roll graph. Note that the (weighted) adjacency matrix **A** is already provided. If it was not the case, we would need to build a similarity graph (using nearest neighbors or an epsilon-neighborhood)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b135fd",
   "metadata": {
    "id": "a13f5249",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 200\n",
    "\n",
    "\n",
    "def sample_signal(n, num_classes=3, num_labels_per_class=4, seed=0):\n",
    "    npr.seed(seed)\n",
    "    indices = npr.choice(n,\n",
    "                         size= num_labels_per_class * num_classes,\n",
    "                         replace=False)\n",
    "    indices = indices.reshape(num_labels_per_class, num_classes)\n",
    "\n",
    "    x = np.zeros((n, num_classes))\n",
    "    for j in range(num_classes):\n",
    "        x[indices[:, j], j] = 1\n",
    "    return x\n",
    "\n",
    "\n",
    "swiss_roll = pygsp.graphs.SwissRoll(n, dim=2, noise=0.05)\n",
    "A = swiss_roll.W                    # weighted adjacency matrix\n",
    "coords = swiss_roll.coords          # coordinates\n",
    "x = sample_signal(n)\n",
    "\n",
    "swiss_roll.plot()\n",
    "\n",
    "plt.figure()\n",
    "c=np.argmax(x, axis=1)\n",
    "plt.scatter(coords[:, 0], coords[:, 1], c=np.argmax(x, axis=1))\n",
    "plt.scatter(coords[:, 0], coords[:, 1], c=x)\n",
    "plt.title(\"Initial labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8fe404",
   "metadata": {
    "id": "85a640c7"
   },
   "source": [
    "**Question 11 (code): Go through the paper and implement the label propagation algorithm of section 2.2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5b2bff",
   "metadata": {
    "id": "114da417"
   },
   "outputs": [],
   "source": [
    "class LabelPropagation():\n",
    "    def __init__(self, num_iters, stopping_criterion=None):\n",
    "        self.num_iters = num_iters\n",
    "        self.stopping_criterion = stopping_criterion\n",
    "    \n",
    "    def __call__(self, A, x, coords, plot_each_iteration=True):\n",
    "        \"\"\" A: n x n: weighted adjacency matrix\n",
    "            x: n x d matrix containing the initial labels\n",
    "            coords: n x 2 matrix containing the point coordinates.\n",
    "            plot_each_iteration: bool.\n",
    "            Return:\n",
    "            pred: n x d prediction matrix (each row should sum to 1)\n",
    "        \"\"\"\n",
    "        plt.figure()\n",
    "        plt.scatter(coords[:, 0], coords[:, 1], c=x)\n",
    "        plt.title(f\"Initial state\")\n",
    "        plt.show()\n",
    "        \n",
    "        # write your code here\n",
    "\n",
    "        for i in range(self.num_iters):\n",
    "            \n",
    "            # write your code here\n",
    "                \n",
    "            if plot_each_iteration:\n",
    "                plt.figure()\n",
    "                plt.scatter(coords[:, 0], coords[:, 1], c=x)\n",
    "                plt.title(f\"After Iteration {i}\")\n",
    "                plt.show()\n",
    "                \n",
    "            if self.stopping_criterion is not None:\n",
    "                if self.stopping_criterion.step(x):\n",
    "                    print(f\"Stopping criterion triggered after {i} iterations.\")\n",
    "                    break\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def plot_predictions(x, coords):\n",
    "    \"\"\" x: n x d matrix containing the predictions \"\"\"\n",
    "    predictions = np.argmax(x, axis=1)\n",
    "    y = np.zeros(x.shape)\n",
    "    for i in range(x.shape[0]):\n",
    "        y[i, predictions[i]] = 1\n",
    "    plt.figure()\n",
    "    plt.scatter(coords[:, 0], coords[:, 1], c=y)\n",
    "    plt.title(\"Final predictions\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550fd4f8",
   "metadata": {
    "id": "b18d3da6"
   },
   "outputs": [],
   "source": [
    "num_iters = 20\n",
    "lp = LabelPropagation(num_iters)\n",
    "predictions = lp(A, x, coords)\n",
    "plot_predictions(predictions, coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9996aa01",
   "metadata": {
    "id": "75557d08"
   },
   "source": [
    "We will add a stopping criterion to our algorithm, and stop training when the updates of all points $i$ satisfy $||x_i^{t+1} - x_i^t||_2 \\leq \\epsilon$.\n",
    "\n",
    "**Question 13 (code): Implement the uniform variation criterion.** *You can use the function `scipy.linalg.norm`*.\n",
    "\n",
    "Tip: don't forget that unexpected behaviours can happen when arrays are modified in place. To avoid this, you can use `np.copy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951767a7",
   "metadata": {
    "id": "d5f7b428"
   },
   "outputs": [],
   "source": [
    "class UniformVariationCriterion():\n",
    "    def __init__(self, threshold=0.01):\n",
    "        self.threshold = threshold\n",
    "        self.last_values = None\n",
    "        \n",
    "    def step(self, x):\n",
    "        \"\"\" Return True if the class probabilities for each point have changed by less than epsilon,\n",
    "            False otherwise.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0280ea6",
   "metadata": {
    "id": "7fdc847c"
   },
   "outputs": [],
   "source": [
    "stopping_criterion = UniformVariationCriterion()\n",
    "num_iters = 200\n",
    "\n",
    "x = sample_signal(n)\n",
    "lp = LabelPropagation(num_iters, stopping_criterion)\n",
    "predictions = lp(A, x, coords, plot_each_iteration=False)\n",
    "plot_predictions(predictions, coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b5525",
   "metadata": {},
   "source": [
    "An alternative way to perform semi-supervised learning is to apply a low-pass filter on the signal. Use the functions defined in the previous exercices to apply a Tikhonov filter with $\\alpha=1$ to the signal `x`.\n",
    "\n",
    "**Question 14 (code): Connection with low-pass filtering. Use the functions defined in the previous exercices to compute a Tikhonov filter. Apply this filter to the signal `x` to compute predictions for unseen nodes.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1640cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "filtered = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f25097",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(filtered, coords)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment 2 questions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
